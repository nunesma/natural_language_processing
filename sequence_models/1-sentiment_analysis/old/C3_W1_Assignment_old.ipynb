{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1:  Sentiment with Deep Neural Networks\n",
    "\n",
    "Welcome to the first assignment of course 3. In this assignment you will explore sentiment analysis using deep neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [0 Import libraries and try out Trax](#0)\n",
    "- [1 Importing the data](#1)\n",
    "    - [1.2 Building the vocabulary](#1.2)\n",
    "    - [1.3 Converting a tweet to a tensor](#1.3)\n",
    "        - [Exercise 01](#ex01)\n",
    "    - [1.4 Creating a batch generator](#1.4)\n",
    "        - [Exercise 02](#ex02)\n",
    "    - [2: Defining classes](#2)\n",
    "    - [2.1 ReLU class](#1.2)\n",
    "        - [Exercise 03](#ex03)\n",
    "    - [2.2 Dense class](#2.2)\n",
    "        - [Exercise 04](#ex04)\n",
    "    - [2.3: Model](#2.3)\n",
    "        - [Exercise 05](#ex05)\n",
    "- [3 Training](#3)\n",
    "    - [3.1 Training the Model](#3.1)\n",
    "        - [Exercise 06](#ex06)\n",
    "    - [3.2 Initialize a model with the trained weights](#3.2)\n",
    "    - [3.3 Practice Making a prediction](#3.3)\n",
    "- [4: Evaluation](#4)\n",
    "    - [4.1 Computing the accuracy on a batch](#4.1)\n",
    "        - [Exercise 07](#ex07)\n",
    "    - [4.2 Testing your model on Validation Data](#4.2)\n",
    "        - [Exercise 08](#ex08)\n",
    "- [5: Testing with your own input](#5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8aeCPdILgrga"
   },
   "source": [
    "In course 1, you implemented Logistic regression and Naive Bayes for sentiment analysis. However if you were to give your old models an example like:\n",
    "\n",
    "<center> <span style='color:blue'> <b>This movie was almost good.</b> </span> </center>\n",
    "\n",
    "Your model would have predicted a positive sentiment for that review. However, that sentence has a negative sentiment and indicates that the movie was not good. To solve those kinds of misclassifications, you will write a program that uses deep neural networks to identify sentiment on text. By completing this assignment you will: \n",
    "\n",
    "- Understand how you can build/design a model in tensorflow\n",
    "- Train a model in tensorflow\n",
    "- Use a binary cross entropy loss function\n",
    "- Compute the accuracy of your model\n",
    "- Predict using your own input\n",
    "\n",
    "As you can tell, this model follows a similar structure to the one you previously implemented in the second course of this specialization. \n",
    "- Indeed most of the deep nets you will be implementing will have a similar structure. The only thing that changes is the model architecture, the inputs, and the outputs. Before starting the assignment, we will show you some cool functionalities of the latest google tensorflow update `trax`. \n",
    "\n",
    "\n",
    "Now we will show you how to compute the gradient of a certain function `f` by just using `trax.math.grad(f)`. \n",
    "\n",
    "- Trax source code can be found on Github: [trax](https://github.com/google/trax).\n",
    "- The Trax code also uses the JAX library: [JAX](https://jax.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "# Part 0: Import libraries and try out Trax\n",
    "\n",
    "- Let's import libraries and look at an example of using the trax library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic gradient with replaced numpy.\n",
    "#!pip -q install trax==1.2.4 # coursera\n",
    "\n",
    "# import relevant libraries\n",
    "import trax\n",
    "\n",
    "# import trax.math.numpy\n",
    "import trax.math.numpy as np\n",
    "\n",
    "# import trax.layers\n",
    "from trax import layers as tl\n",
    "\n",
    "# import Layer from the utils.py file\n",
    "from utils import Layer\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array using trax.math.numpy\n",
    "a = np.array(5.0)\n",
    "\n",
    "# View the returned array\n",
    "display(a)\n",
    "\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that trax.math.numpy returns a DeviceArray from the jax library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will use the trax.math.numpy array\n",
    "def f(x):\n",
    "    \n",
    "    # f = x^2\n",
    "    return (x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "print(\"f(a) for a is\", f(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient (derivative) of function `f` with respect to its input `x` is the derivative of $x^2$.\n",
    "- The derivative of $x^2$ is $2x$.  \n",
    "- When x is 5, then $2x=10$.\n",
    "\n",
    "You can calculate the gradient of a function by using `trax.math.grad(fun=)` and passing in the name of the function.\n",
    "- In this case the function you want to take the gradient of is `f`.\n",
    "- The object returned (saved in `grad_f` in this example) is a function that can calculate the gradient of f for a given trax.math.numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly use trax.math.grad to calculate the gradient (derivative) of the function\n",
    "grad_f = trax.math.grad(fun=f)  # df / dx - Gradient of function f(x) with respect to x\n",
    "\n",
    "# View the type of the retuned object (it's a function)\n",
    "type(grad_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the newly created function and pass in a value for x (the DeviceArray stored in 'a')\n",
    "grad_calculation = grad_f(a)\n",
    "\n",
    "# View the result of calling the grad_f function\n",
    "display(grad_calculation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returned by trax.math.grad returns takes in x=5 and calculates the gradient of f, which is 2*x, which is 10. The value is also stored as a DeviceArray from the jax library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZ8RUynQsktn"
   },
   "source": [
    "<a name='1'></a>\n",
    "# Part 1: Importing the data\n",
    "\n",
    "### 1.1 Loading in the data\n",
    "\n",
    "Import the data set.  \n",
    "- You may recognize this from earlier assignments in the specialization.\n",
    "- Details of process_tweet function is available in utils.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "h5ClwIOSuLJh",
    "outputId": "71b65197-0358-45c0-be58-18f48524ed03"
   },
   "outputs": [],
   "source": [
    "## DO NOT EDIT THIS CELL\n",
    "\n",
    "# Import functions from the utils.py file\n",
    "from utils import load_tweets\n",
    "import numpy as np\n",
    "\n",
    "# Load positive and negative tweets\n",
    "all_positive_tweets, all_negative_tweets = load_tweets()\n",
    "\n",
    "# View the total number of positive and negative tweets.\n",
    "print(f\"The number of positive tweets: {len(all_positive_tweets)}\")\n",
    "print(f\"The number of negative tweets: {len(all_negative_tweets)}\")\n",
    "\n",
    "# Split positive set into validation and training\n",
    "val_pos   = all_positive_tweets[4000:] # generating validation set for positive tweets\n",
    "train_pos  = all_positive_tweets[:4000]# generating training set for positive tweets\n",
    "\n",
    "# Split negative set into validation and training\n",
    "val_neg   = all_negative_tweets[4000:] # generating validation set for negative tweets\n",
    "train_neg  = all_negative_tweets[:4000] # generating training set for nagative tweets\n",
    "\n",
    "# Combine training data into one set\n",
    "train_x = train_pos + train_neg \n",
    "\n",
    "# Combine validation data into one set\n",
    "val_x  = val_pos + val_neg\n",
    "\n",
    "# Set the labels for the training set (1 for positive, 0 for negative)\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "\n",
    "# Set the labels for the validation set (1 for positive, 0 for negative)\n",
    "val_y  = np.append(np.ones(len(val_pos)), np.zeros(len(val_neg)))\n",
    "\n",
    "print(f\"length of train_x {len(train_x)}\")\n",
    "print(f\"length of val_x {len(val_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import a function that processes tweets (we've provided this in the utils.py file).\n",
    "- `process_tweets' removes unwanted characters e.g. hashtag, hyperlinks, stock tickers from tweet.\n",
    "- It also returns a list of words (it tokenizes the original string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a function that processes the tweets\n",
    "from utils import process_tweet\n",
    "\n",
    "# Try out function that processes tweets\n",
    "print(\"original tweet at training position 0\")\n",
    "print(train_pos[0])\n",
    "\n",
    "print(\"Tweet at training position 0 after processing:\")\n",
    "process_tweet(train_pos[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the function `process_tweet` keeps key words, removes the hash # symbol, and ignores usernames (words that begin with '@').  It also returns a list of the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ac4D5WSUAVub"
   },
   "source": [
    "<a name='1.2'></a>\n",
    "### 1.2 Building the vocabulary\n",
    "\n",
    "Now build the vocabulary.\n",
    "- Map each word in each tweet to an integer (an \"index\"). \n",
    "- The following code does this for you, but please read it and understand what it's doing.\n",
    "- Note that you will build the vocabulary based on the training data. \n",
    "- To do so, you will assign an index to everyword by iterating over your training set.\n",
    "\n",
    "The vocabulary will also include some special tokens\n",
    "- `__PAD__`: padding\n",
    "- `</e>`: end of line\n",
    "- `__UNK__`: a token representing any word that is not in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQaHKs7kAVuc",
    "outputId": "d2c06e31-ccbb-4095-d35f-cd4477e8d507"
   },
   "outputs": [],
   "source": [
    "# Build the vocabulary\n",
    "# Unit Test Note - There is no test set here only train/val\n",
    "\n",
    "# Include special tokens \n",
    "# started with pad, end of line and unk tokens\n",
    "Vocab = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2} \n",
    "\n",
    "# Note that we build vocab using training data\n",
    "for tweet in train_x: \n",
    "    processed_tweet = process_tweet(tweet)\n",
    "    for word in processed_tweet:\n",
    "        if word not in Vocab: \n",
    "            Vocab[word] = len(Vocab)\n",
    "    \n",
    "print(\"Total words in vocab are\",len(Vocab))\n",
    "display(Vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gP6K9qcCAVue"
   },
   "source": [
    "The dictionary `Vocab` will look like this:\n",
    "```CPP\n",
    "{'__PAD__': 0,\n",
    " '__</e>__': 1,\n",
    " '__UNK__': 2,\n",
    " 'followfriday': 3,\n",
    " 'top': 4,\n",
    " 'engag': 5,\n",
    " ...\n",
    "```\n",
    "\n",
    "- Each unique word has a unique integer associated with it.\n",
    "- The total number of words in Vocab: 9092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0x8pND8tAVuf"
   },
   "source": [
    "<a name='1.3'></a>\n",
    "### 1.3 Converting a tweet to a tensor\n",
    "\n",
    "Write a function that will convert each tweet to a tensor (a list of unique integer IDs representing the processed tweet).\n",
    "- Note, the returned data type will be a **regular Python `list()`**\n",
    "    - You won't use TensorFlow in this function\n",
    "    - You also won't use a numpy array\n",
    "    - You also won't use trax.math.numpy array\n",
    "- For words in the tweet that are not in the vocabulary, set them to the unique ID for the token `__UNK__`.\n",
    "\n",
    "##### Example\n",
    "Input a tweet:\n",
    "```CPP\n",
    "'@happypuppy, is Maria happy?'\n",
    "```\n",
    "\n",
    "The tweet_to_tensor will first conver the tweet into a list of tokens (including only relevant words)\n",
    "```CPP\n",
    "['maria', 'happi']\n",
    "```\n",
    "\n",
    "Then it will convert each word into its unique integer\n",
    "\n",
    "```CPP\n",
    "[2, 56]\n",
    "```\n",
    "- Notice that the word \"maria\" is not in the vocabulary, so it is assigned the unique integer associated with the `__UNK__` token, because it is considered \"unknown.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex01'></a>\n",
    "### Exercise 01\n",
    "**Instructions:** Write a program `tweet_to_tensor` that takes in a tweet and converts it to an array of numbers. You can use the `Vocab` dictionary you just found to help create the tensor. \n",
    "\n",
    "- Use the vocab_dict parameter and not a global variable.\n",
    "- Do not hard code the integer value for the `__UNK__` token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Map each word in tweet to corresponding token in 'Vocab'</li>\n",
    "    <li>Use Python's Dictionary.get(key,value) so that the function returns a default value if the key is not found in the dictionary.</li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ft1zNGMaAVuf",
    "outputId": "67f021bf-cee2-4294-ad1a-1e19c0331443"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: tweet_to_tensor\n",
    "def tweet_to_tensor(tweet, vocab_dict, unk_token='__UNK__', verbose=False):\n",
    "    \n",
    "    # Process the tweet into a list of words\n",
    "    # where only important words are kept (stop words removed)\n",
    "    word_l = None\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"List of words from the processed tweet:\")\n",
    "        print(word_l)\n",
    "        \n",
    "    # Initialize the list that will contain the unique integer IDs of each word\n",
    "    tensor_l = []\n",
    "    \n",
    "    # Get the unique integer ID of the __UNK__ token\n",
    "    unk_ID = None\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"The unique integer ID for the unk_token is {unk_ID}\")\n",
    "        \n",
    "    # for each word in the list:\n",
    "    for word in None: # complete this line\n",
    "        \n",
    "        # Get the unique integer ID.\n",
    "        # If the word doesn't exist in the vocab dictionary,\n",
    "        # use the unique ID for __UNK__ instead.\n",
    "        word_ID = None\n",
    "            \n",
    "        # Append the unique integer ID to the tensor list.\n",
    "        tensor_l.append(word_ID) \n",
    "    \n",
    "    return tensor_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual tweet is\\n\",val_pos[0])\n",
    "print(\"\\nTensor of tweet:\\n\",tweet_to_tensor(val_pos[0], vocab_dict=Vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected output\n",
    "\n",
    "```CPP\n",
    "Actual tweet is\n",
    " Bro:U wan cut hair anot,ur hair long Liao bo\n",
    "Me:since ord liao,take it easy lor treat as save $ leave it longer :)\n",
    "Bro:LOL Sibei xialan\n",
    "\n",
    "Tensor of tweet:\n",
    " [1065, 136, 479, 2351, 745, 8146, 1123, 745, 53, 2, 2672, 791, 2, 2, 349, 601, 2, 3489, 1017, 597, 4559, 9, 1065, 157, 2, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test tweet_to_tensor\n",
    "\n",
    "def test_tweet_to_tensor():\n",
    "    test_cases = [\n",
    "        \n",
    "        {\n",
    "            \"name\":\"simple_test_check\",\n",
    "            \"input\": [val_pos[1],Vocab],\n",
    "            \"expected\":[444, 2, 304, 567, 56, 9],\n",
    "            \"error\":\"The function gives bad output for val_pos[1]. Test failed\"\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"datatype_check\",\n",
    "            \"input\":[val_pos[1],Vocab],\n",
    "            \"expected\":type([]),\n",
    "            \"error\":\"Datatype mismatch. Need only list not np.array\"\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"without_unk_check\",\n",
    "            \"input\":[val_pos[1],Vocab],\n",
    "            \"expected\":6,\n",
    "            \"error\":\"Unk word check not done- Please check if you included mapping for unknown word\"\n",
    "        }\n",
    "    ]\n",
    "    count = 0\n",
    "    for test_case in test_cases:\n",
    "        \n",
    "        try:\n",
    "            if test_case['name'] == \"simple_test_check\":\n",
    "                assert test_case[\"expected\"] == tweet_to_tensor(*test_case['input'])\n",
    "                count += 1\n",
    "            if test_case['name'] == \"datatype_check\":\n",
    "                assert isinstance(tweet_to_tensor(*test_case['input']),test_case[\"expected\"])\n",
    "                count += 1\n",
    "            if test_case['name'] == \"without_unk_check\":\n",
    "                assert None not in tweet_to_tensor(*test_case['input'])\n",
    "                count += 1\n",
    "                \n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print(test_case['error'])\n",
    "    if count == 3:\n",
    "        print(\"all tests passed\")\n",
    "    else:\n",
    "        print(count,\" Tests passed out of 3\")\n",
    "test_tweet_to_tensor()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwAZZIYYAVuj"
   },
   "source": [
    "<a name='1.4'></a>\n",
    "### 1.4 Creating a batch generator\n",
    "\n",
    "Most of the time in Natural Language Processing, and AI in general we use batches when training our data sets. \n",
    "- If instead of training with batches of examples, you were to train a model with one example at a time, it would take a very long time to train the model. \n",
    "- You will now build a data generator that takes in the positive/negative tweets and returns a batch of training examples. It returns the model inputs and the targets (positive or negative labels). \n",
    "\n",
    "Once you create the generator, you could include it in a for loop\n",
    "\n",
    "```CPP\n",
    "for batch_inputs, batch_targets in data_generator:\n",
    "    ...\n",
    "```\n",
    "\n",
    "You can also get a single batch like this:\n",
    "\n",
    "```CPP\n",
    "batch_inputs, batch_targets = next(data_generator)\n",
    "```\n",
    "The generator returns the next batch each time it's called. \n",
    "- This generator returns the data in a format (tensors) that you could directly use in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex02'></a>\n",
    "### Exercise 02\n",
    "Implement `data_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPd9HNT7AVuk"
   },
   "outputs": [],
   "source": [
    "# GRADED: Data generator\n",
    "def data_generator(data_pos, data_neg, batch_size, loop, vocab_dict):\n",
    "    \n",
    "    '''\n",
    "    Input: \n",
    "     data_pos - Set of posstive examples\n",
    "     data_neg - Set of negative examples\n",
    "     batch_size - number of samples per batch\n",
    "     loop - True or False\n",
    "    '''   \n",
    "### START GIVEN CODE ###\n",
    "\n",
    "    # make sure the batch size is an even number\n",
    "    # to allow an equal number of positive and negative samples\n",
    "    assert batch_size % 2 == 0\n",
    "    \n",
    "    # Number of positive examples in each batch is half of the batch size\n",
    "    # same with number of negative examples in each batch\n",
    "    n_to_take = batch_size // 2\n",
    "    \n",
    "    # Use pos_index to walk through the data_pos array\n",
    "    # same with neg_index and data_neg\n",
    "    pos_index = 0\n",
    "    neg_index = 0\n",
    "    \n",
    "    # Loop indefinitely\n",
    "    while True:\n",
    "        \n",
    "        # If the positive index plus num of positive examples\n",
    "        # goes past the positive dataset,\n",
    "        if pos_index + n_to_take > len(data_pos): \n",
    "            \n",
    "            # If user wants to keep re-using the data, reset the index\n",
    "            if loop:\n",
    "                pos_index = 0\n",
    "                \n",
    "            # otherwise exit the loop\n",
    "            else:\n",
    "                # exit the loop\n",
    "                break\n",
    "### END GIVEN CODE ###\n",
    "\n",
    "### START CODE HERE ###\n",
    "        # If the positive index plus num of negative examples\n",
    "        # goes past the negative dataset,\n",
    "        if None: # complete this line\n",
    "            # If user wants to keep re-using the data, reset the index\n",
    "            if loop:\n",
    "                \n",
    "                # Reset the negative index\n",
    "                neg_index = None\n",
    "                \n",
    "            # otherwise exit the loop\n",
    "            else:\n",
    "                # exit the loop\n",
    "                None\n",
    "### END CODE HERE ###\n",
    "\n",
    "### START GIVEN CODE ###\n",
    "        # create a batch with positive examples\n",
    "        batch = []\n",
    "        \n",
    "        # Start from pos_index and increment i up to n_to_take\n",
    "        for i in range(n_to_take):\n",
    "            # get the tweet as pos_index + i\n",
    "            tweet = data_pos[pos_index + i]\n",
    "            \n",
    "            # convert the tweet into tensors of integers representing the processed words\n",
    "            tensor = tweet_to_tensor(tweet,vocab_dict)\n",
    "            \n",
    "            # append the tensor to the batch list\n",
    "            batch.append(tensor)\n",
    "\n",
    "### END GIVEN CODE ###\n",
    "            \n",
    "### START CODE HERE ###\n",
    "\n",
    "        # Using the same batch list, start from neg_index and increment i up to n_to_take\n",
    "        for i in range(None): # complete this line\n",
    "            # get the tweet as pos_index + i\n",
    "            tweet = None\n",
    "            \n",
    "            # convert the tweet into tensors of integers representing the processed words\n",
    "            tensor = None\n",
    "            \n",
    "            # append the tensor to the batch list\n",
    "            None\n",
    "\n",
    "### END CODE HERE ###        \n",
    "\n",
    "\n",
    "### START GIVEN CODE ###\n",
    "\n",
    "        # Update the start index for positive data \n",
    "        # so that it's n_to_take positions after the current pos_index\n",
    "        pos_index += n_to_take\n",
    "        \n",
    "        # Update the start index for negative data \n",
    "        # so that it's n_to_take positions after the current neg_index\n",
    "        neg_index += n_to_take\n",
    "        \n",
    "        # Get the max tweet length (the length of the longest tweet) \n",
    "        # (you will pad all shorter tweets to have this length)\n",
    "        max_len = max([len(t) for t in batch]) \n",
    "        \n",
    "        # Initialize the input_l, which will \n",
    "        # store the padded versions of the tensors\n",
    "        tensor_pad_l = []\n",
    "        # Pad shorter tweets with zeros\n",
    "        for tensor in batch:\n",
    "            \n",
    "### END GIVEN CODE ###\n",
    "\n",
    "### START CODE HERE ###            \n",
    "            # Get the number of positions to pad for this tensor so that it will be max_len long\n",
    "            n_pad = None\n",
    "            \n",
    "            # Generate a list of zeros, with length n_pad\n",
    "            pad_l = None\n",
    "            \n",
    "            # concatenate the tensor and the list of padded zeros\n",
    "            tensor_pad = None\n",
    "            \n",
    "            # append the padded tensor to the list of padded tensors\n",
    "            None\n",
    "\n",
    "          \n",
    "        # convert the list of padded tensors to a numpy array\n",
    "        # and store this as the model inputs\n",
    "        inputs = None\n",
    "  \n",
    "        # Generate the list of targets for the positive examples (a list of ones)\n",
    "        # The length is the number of positive examples in the batch\n",
    "        target_pos = None\n",
    "        \n",
    "        # Generate the list of targets for the negative examples (a list of ones)\n",
    "        # The length is the number of negative examples in the batch\n",
    "        target_neg = None\n",
    "        \n",
    "        # Concatenate the positve and negative targets\n",
    "        target_l = None\n",
    "        \n",
    "        # Convert the target list into a numpy array\n",
    "        targets = None\n",
    "             \n",
    "### END CODE HERE ###\n",
    "\n",
    "### GIVEN CODE ###\n",
    "        # note we use yield and not return\n",
    "        yield inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use your data generator to create a data generator for the training data, and another data generator for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIwM4YHtAVum",
    "outputId": "45352be1-d538-4682-bd90-e523fbbef1a9"
   },
   "outputs": [],
   "source": [
    "# Create the training data generator\n",
    "def train_generator(batch_size):\n",
    "    return data_generator(train_pos, train_neg, batch_size, True, Vocab)\n",
    "\n",
    "# Create the test data generator\n",
    "def val_generator(batch_size):\n",
    "    return data_generator(val_pos, val_neg, batch_size, False, Vocab)\n",
    "\n",
    "# this will print a list of 4 tensors padded with zeros\n",
    "print(next(train_generator(4))) # use next to get a new batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the train_generator\n",
    "\n",
    "# Create a data generator for training data,\n",
    "# which produces batches of size 4 (for tensors and their respective targets)\n",
    "tmp_data_gen = train_generator(batch_size = 4)\n",
    "\n",
    "# Call the data generator to get one batch and its targets\n",
    "tmp_inputs, tmp_targets = next(tmp_data_gen)\n",
    "\n",
    "print(f\"The inputs shape is {tmp_inputs.shape}\")\n",
    "for i,t in enumerate(tmp_inputs):\n",
    "    print(f\"input tensor: {t}; target {tmp_targets[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected output\n",
    "\n",
    "```CPP\n",
    "The inputs shape is (4, 14)\n",
    "input tensor: [3 4 5 6 7 8 9 0 0 0 0 0 0 0]; target 1\n",
    "input tensor: [10 11 12 13 14 15 16 17 18 19 20  9 21 22]; target 1\n",
    "input tensor: [5738 2901 3761    0    0    0    0    0    0    0    0    0    0    0]; target 0\n",
    "input tensor: [ 858  256 3652 5739  307 4458  567 1230 2767  328 1202 3761    0    0]; target 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J3HrgcJmAVup"
   },
   "source": [
    "Now that you have your train/val generators, you can just call them and they will return tensors which correspond to your tweets in the first column and their corresponding labels in the second column. Now you can go ahead and start building your neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X591GrH_stXq"
   },
   "source": [
    "<a name='2'></a>\n",
    "# Part 2: Defining classes\n",
    "\n",
    "We have given you the `Layer` class in the utils.py.\n",
    "\n",
    "```CPP\n",
    "class Layer(object):\n",
    "    \"\"\" Base class for layers.\n",
    "    \"\"\"\n",
    "      \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        # set weights to None\n",
    "        self.weights = None\n",
    "\n",
    "    # The forward propagation should be implemented\n",
    "    # by the subclass of this Layer class\n",
    "    def forward(self, x, weights):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # This function returns new weights\n",
    "    # based on the input signature and random key\n",
    "    def new_weights(self, input_signature, random_key):\n",
    "        return ()\n",
    "\n",
    "    # This initializes the weights\n",
    "    def init(self, input_signature, random_key):\n",
    "        self.weights = self.new_weights(input_signature, random_key)\n",
    "\n",
    "    # __call__ allows an object of this class\n",
    "    # to be called like it's a function.\n",
    "    def __call__(self, x):\n",
    "        # When this layer object is called, \n",
    "        # it calls its forward propagation function\n",
    "        return self.forward(x, self.weights)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcWUXFaPzS-m"
   },
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 ReLU class\n",
    "You will now implement the ReLU activation function in a class below. The ReLU function looks as follows: \n",
    "<img src = \"relu.jpg\" style=\"width:300px;height:150px;\"/>\n",
    "\n",
    "$$ \\mathrm{reLU}(x) = \\mathrm{max}(0,x) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex03'></a>\n",
    "### Exercise 03\n",
    "**Instructions:** Implement the ReLU activation function below. Your function should take in a matrix or vector and it should transform all the negative numbers into 0 while keeping all the positive numbers intact. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Please use numpy.maximum(A,k) to find the maximum between each element in A and a scalar k</li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VGE5zZ5mzF9x"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: Relu\n",
    "class Relu(Layer):\n",
    "    \"\"\"Relu activation function implementation\"\"\"\n",
    "    def forward(self, x, weights):\n",
    "        '''\n",
    "        Input: \n",
    "            - x (a numpy array): the input\n",
    "            - weights: Not used for relu, but is included to inherit from Layer class\n",
    "        Output:\n",
    "            - activation (numpy array): all positive or 0 version of x\n",
    "        '''\n",
    "        # Delete the weights parameter because it's not used for \n",
    "        # this Relu subclass of Layer\n",
    "        del weights \n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        activation = None\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hVQ3YtoZ1uYP",
    "outputId": "aadbb2cf-ea26-486e-f21a-867824e98a78"
   },
   "outputs": [],
   "source": [
    "# Test your relu function\n",
    "x = np.array([[-2.0, -1.0, 0.0], [0.0, 1.0, 2.0]], dtype=float)\n",
    "relu_layer = Relu()\n",
    "print(\"Test data is:\")\n",
    "print(x)\n",
    "print(\"Output of Relu is:\")\n",
    "print(relu_layer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "niL6mIuBAVuu"
   },
   "source": [
    "##### Expected Outout\n",
    "```CPP\n",
    "Test data is:\n",
    "[[-2. -1.  0.]\n",
    " [ 0.  1.  2.]]\n",
    "Output of Relu is:\n",
    "[[0. 0. 0.]\n",
    " [0. 1. 2.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XepjDxCQ1G8p"
   },
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 Dense class \n",
    "\n",
    "### Exercise\n",
    "\n",
    "Implement the forward function of the Dense class. \n",
    "- The forward function multiplies the input to the layer (`x`) by the weight matrix (`weights`)\n",
    "\n",
    "$$\\mathrm{forward}(\\mathbf{x},\\mathbf{weights}) = \\mathbf{x} \\times \\mathbf{weights}$$\n",
    "\n",
    "- You can use `numpy.dot` to perform the matrix multiplication.\n",
    "\n",
    "Note that for more efficient code execution, you will use the trax version of `math`, which includes a trax version of `numpy` and also `random`.\n",
    "\n",
    "Implement the weight initializer `new_weights` function\n",
    "- Weights are initialized with a random key.\n",
    "- The second parameter is a tuple for the desired shape of the weights (num_rows, num_cols)\n",
    "- The num of rows for weights should equal the number of columns in x, because for forward propagation, you will multiply x times weights.\n",
    "\n",
    "Please use `trax.math.random.normal(key, shape, dtype=tf.float32)` to generate random values for the weight matrix.\n",
    "- `key` can be generated by calling `random.get_prng(seed=)` and passing in a number for the `seed`.\n",
    "- `shape` is a tuple with the desired shape of the weight matrix.\n",
    "    - The number of rows in the weight matrix should equal the number of columns in the variable `x`.  Since `x` may have 2 dimensions if it reprsents a single training example (row, col), or three dimensions (batch_size, row, col), get the last dimension from the tuple that holds the dimensions of x.\n",
    "    - The number of columns in the weight matrix is the number of units chosen for that dense layer.  Look at the `__init__` function to see which variable stores the number of units.\n",
    "- `dtype` is the data type of the values in the generated matrix; keep the default of `tf.float32`. In this case, don't explicitly set the dtype (just let it use the default value).\n",
    "\n",
    "Set the standard deviation of the random values to 0.1\n",
    "- The values generated have a mean of 0 and standard deviation of 1.\n",
    "- Set the default standard deviation `stdev` to be 0.1 by multiplying the standard deviation to each of the values in the weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the math module within trax\n",
    "from trax import math\n",
    "\n",
    "# use the numpy module from trax\n",
    "np = math.numpy\n",
    "\n",
    "# use the math.random module from trax\n",
    "random = math.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how the math.trax.random.normal function works\n",
    "tmp_key = random.get_prng(seed=1)\n",
    "print(\"The random seed generated by random.get_prng\")\n",
    "display(tmp_key)\n",
    "\n",
    "print(\"choose a matrix with 2 rows and 3 columns\")\n",
    "tmp_shape=(2,3)\n",
    "display(tmp_shape)\n",
    "\n",
    "# Generate a weight matrix\n",
    "# Note that you'll get an error if you try to set dtype to tf.float32, where tf is tensorflow\n",
    "# Just avoid setting the dtype and allow it to use the default data type\n",
    "tmp_weight = trax.math.random.normal(key=tmp_key, shape=tmp_shape)\n",
    "\n",
    "print(\"Weight matrix generated with a normal distribution with mean 0 and stdev of 1\")\n",
    "display(tmp_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex04'></a>\n",
    "### Exercise 04\n",
    "\n",
    "Implement the `Dense` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "783FfWt70660"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: Dense\n",
    "\n",
    "class Dense(Layer):\n",
    "    \"\"\"\n",
    "    A dense (fully-connected) layer.\n",
    "    \"\"\"\n",
    "\n",
    "    # __init__ is implemented for you\n",
    "    def __init__(self, n_units):\n",
    "        \n",
    "        # Set the number of units in this layer\n",
    "        self._n_units = n_units\n",
    "\n",
    "    # Please implement 'forward()'\n",
    "    def forward(self, x, weights):\n",
    "        ### START CODE HERE ###\n",
    "        # Matrix multiply x and the weight matrix\n",
    "        dense = None\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        return dense\n",
    "\n",
    "    # new_weights\n",
    "    def new_weights(self, input_signature, random_key, stdev=0.1):\n",
    "        \n",
    "### START CODE HERE ###\n",
    "        # The input_signature has a .shape attribute that gives the shape as a tuple\n",
    "        input_shape = None\n",
    "\n",
    "        # Generate the weight matrix from a normal distribution, \n",
    "        # and standard deviation of 'stdev'        \n",
    "        w = None\n",
    "        \n",
    "### END CODE HERE ###     \n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vw-z6n8SAVuy",
    "outputId": "466dfcbf-dc44-4b4f-a005-78e8313a6fcb"
   },
   "outputs": [],
   "source": [
    "# Testing your Dense layer \n",
    "dense_layer = Dense(n_units=10)  #sets  number of units in dense layer\n",
    "random_key = random.get_prng(seed=0)  # sets random seed\n",
    "z = np.array([[2.0, 7.0, 25.0]]) # input array \n",
    "\n",
    "# CODE REVIEW - Dense object .init calls what exactly should be clarified \n",
    "# as there is no link between init, forward and new_weights.\n",
    "# This dense is of trax layer class and should be given documentation or explaination from the codebase definition of layer\n",
    "# https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/base.py#L243\n",
    "# It returns self._weights, self.state\n",
    "\n",
    "dense_layer.init(z,random_key)\n",
    "print(\"Weights are\\n \",dense_layer.weights) #Returns randomly generated weights\n",
    "print(\"Foward function output is \", dense_layer(z)) # Returns multiplied values of units and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZEY8vBCgrgy"
   },
   "source": [
    "<a name='2.3'></a>\n",
    "### 2.3: Model\n",
    "\n",
    "Now you will implement a classifier using neural networks. Here is the model architecture you will be implementing. \n",
    "\n",
    "<img src = \"nn.jpg\" style=\"width:400px;height:250px;\"/>\n",
    "\n",
    "Note that the second character of `tl` is the lowercase of letter `L`, not the number 1.\n",
    "\n",
    "- [tl.Serial](https://github.com/google/trax/blob/master/trax/layers/combinators.py#L26): Combinator that applies layers serially.  \n",
    "    - You can pass in the layers as arguments to `Serial`, separated by commas. \n",
    "    - For example: `tl.Serial(tl.Embeddings(...), tl.Mean(...), tl.Dense(...), tl.LogSoftmax(...))`\n",
    "\n",
    "Please use the `help` function to view documentation for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View documentation on tl.Serial\n",
    "help(tl.Serial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [tl.Embedding](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L113): Layer constructor function for an embedding layer.  \n",
    "    - `tl.Embedding(d_feature, vocab_size)`.\n",
    "    - `d_feature` is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example).\n",
    "    - `vocab_size` is the number of unique words in the given vocabulary.\n",
    "    - Recall from the previous course 2, week 4, that the embedding is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View documentation for tl.Embedding\n",
    "help(tl.Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_embed = tl.Embedding(d_feature=2,vocab_size=2)\n",
    "display(tmp_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [tl.Mean](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L276): Calculates means across an axis.  In this case, please choose axis = 1 to get an average embedding vector (an embedding vector that is an average of all words in the vocabulary).  \n",
    "- For example, if the embedding matrix is 300 elements and vocab size is 10,000 words, taking the mean of the embedding matrix along axis=1 will yield a vector of 300 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the documentation for tl.mean\n",
    "help(tl.Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretend the embedding matrix uses \n",
    "# 2 elements for embedding the meaning of a word\n",
    "# and has a vocabulary size of 3\n",
    "# So it has shape (2,3)\n",
    "tmp_embed = np.array([[1,2,3,],\n",
    "                    [4,5,6]\n",
    "                   ])\n",
    "\n",
    "# take the mean along axis 0\n",
    "print(\"The mean along axis 0 creates a vector whose length equals the vocabulary size\")\n",
    "display(np.mean(tmp_embed,axis=0))\n",
    "\n",
    "print(\"The mean along axis 1 creates a vector whose length equals the number of elements in a word embedding\")\n",
    "display(np.mean(tmp_embed,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [tl.Dense](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L28): A dense (fully-connected) layer.\n",
    "- `tl.Dense(n_units=)`: The parameter `n_units` is the number of units chosen for this dense layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tl.Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dense = tl.Dense(n_units=2)\n",
    "tmp_dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [tl.LogSoftmax](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L242): Implements log softmax function\n",
    "- Here, you don't need to set any parameters for `LogSoftMax()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tl.LogSoftmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex05'></a>\n",
    "### Exercise 05\n",
    "Implement the classifier function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wh33Hk8lgrgz"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: classifier\n",
    "def classifier(vocab_size=len(Vocab), embedding_dim=256, output_dim=2, mode='train'):\n",
    "    \n",
    "    # create embedding layer\n",
    "    # number of rows is the embedding units\n",
    "    # number of columns is the vocabulary size\n",
    "    embed_layer = None\n",
    "    \n",
    "    # Create a mean layer, to create an \"average\" word embedding\n",
    "    mean_layer = None\n",
    "    \n",
    "    # Create a dense layer, one unit for each output\n",
    "    dense_output_layer = None\n",
    "    \n",
    "    # Create the log softmax layer (no parameters needed)\n",
    "    log_softmax_layer = None\n",
    "    \n",
    "    # Use tl.Serial to combine all layers\n",
    "    # and create the classifier\n",
    "    # of type trax.layers.combinators.Serial\n",
    "    model = None\n",
    "    \n",
    "    # return the model of type\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model = classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tmp_model))\n",
    "display(tmp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected output\n",
    "\n",
    "```\n",
    "<class 'trax.layers.combinators.Serial'>\n",
    "Serial{in=1,out=1,sublayers=[Embedding{in=1,out=1}, Mean{in=1,out=1}, Dense{in=1,out=1}, LogSoftmax{in=1,out=1}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FaugA_7grg6"
   },
   "source": [
    "<a name='3'></a>\n",
    "# Part 3: Training\n",
    "\n",
    "Before, going into the training, we will define the inputs using `trax.supervised.Inputs`\n",
    "- run `help(trax.supervised.Inputs)` for details\n",
    "- You will pass in the data generators that provide processed training & validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View documentation for trax.supervised.Inputs\n",
    "help(trax.supervised.Inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the generators are not considered \"callable\", and you'll get an error message if you pass them to the `trax.supervised.Inputs` like this:\n",
    "\n",
    "```CPP\n",
    "tweet_inputs = trax.supervised.Inputs(\n",
    "      train_stream=train_generator(16), # Keeping the batch size as 16\n",
    "      eval_stream=val_generator(16)) # make this validation set\n",
    "```\n",
    "\n",
    "Error message is:\n",
    "```CPP\n",
    "TypeError: 'generator' object is not callable\n",
    "```\n",
    "\n",
    "In order to pass in a callable function, wrap the each generator in a function.\n",
    "- Notice that the function takes in a single parameter that doesn't appear to be used.\n",
    "- This is needed when trax.supervised.Inputs calls the function and passes in a seed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a callable function that invokes the generator\n",
    "# The parameter x is used when the trax.supervised.Inputs calls this function\n",
    "# and sets a seed value.\n",
    "def train_gen_callable(x):\n",
    "    \n",
    "    return train_generator(16)\n",
    "\n",
    "# Define a callable function that invokes the generator\n",
    "# The parameter x is used when the trax.supervised.Inputs calls this function\n",
    "# and sets a seed value.\n",
    "def val_gen_callable(x):\n",
    "    return val_generator(16)\n",
    "\n",
    "# Use trax.supervised.Inputs\n",
    "# to process the inputs.\n",
    "tweet_inputs = trax.supervised.Inputs(\n",
    "      train_stream=train_gen_callable, \n",
    "      eval_stream=val_gen_callable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more compact way to do the same thing is to use a lambda function, like this:\n",
    "```CPP\n",
    "# Use lambda function to pass in callable functions that can invoke the generators\n",
    "tweet_inputs = trax.supervised.Inputs(\n",
    "      train_stream=lambda x: train_generator(16), # batch size 16\n",
    "      eval_stream=lambda x: val_generator(16))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HA01H6K7grg_"
   },
   "source": [
    "<a name='3.1'></a>\n",
    "### 3.1 Training the model\n",
    "\n",
    "Now you are going to train your model. \n",
    "\n",
    "You will use `trax.supervised.Trainer` to create a model.\n",
    "- Feed in a model\n",
    "- Define the cost function\n",
    "- Choose the optimizer\n",
    "- Choose the learning rate scheduler.\n",
    "- Choose the inputs\n",
    "- Choose and output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use `trax.supervised.Trainer` to create a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View documentation for trax.supervised.Trainer\n",
    "help(trax.supervised.Trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the constructor shows the parameters that you will give to the Trainer.\n",
    "```CPP\n",
    "__init__(self, model, loss_fn, optimizer, lr_schedule, inputs, output_dir=None, ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `trax.supervised.Trainer`\n",
    "- Feed in a model\n",
    "    - For the `model` parameter, pass in the name of the `classifier` function that you defined earlier. (The one which creates the tl.Serial() model.)\n",
    "\n",
    "- define the cost function.\n",
    "    - For the `loss_fn` parameter, choose `tl.CrossEntropyLoss`\n",
    "    - Cross Entropy Loss is used for classification problems that choose between two classes (in this case, positive or negative sentiment).\n",
    "    - Pass in the reference to the function `tl.CrossEntropyLoss` (don't include any parentheses `()` after it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View metrics and loss functions that you could choose from\n",
    "help(trax.layers.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some loss or evaluation metrics include: \n",
    "\n",
    "```CPP\n",
    "AccuracyScalar\n",
    "    \n",
    "CrossEntropyLoss\n",
    "    \n",
    "L2Loss\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View documentation for tl.CrossEntropyLoss\n",
    "help(tl.CrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose the value for the `optimizer` parameter:\n",
    "    - Choose `trax.optimizers.Adam`\n",
    "    - The Adam optimizer is a popular optimizer that tracks a learning weight for each weight and adjusts that learning rate during training.\n",
    "    - Again, just pass in the reference to Adam (no parentheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View optimizers that you could choose from\n",
    "help(trax.optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice some available optimizers include:\n",
    "```CPP\n",
    "adafactor\n",
    "    adam\n",
    "    base\n",
    "    momentum\n",
    "    rms_prop\n",
    "    sgd\n",
    "    sm3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View documentation for trax.optimizers.Adam\n",
    "help(trax.optimizers.Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose the value for the `lr_schedule` parameter, which is the learning rate scheduler.\n",
    "    - Choose `trax.lr.MultifactorSchedule`.  As with the other inputs, just pass in the reference to [MultifactorSchedule](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/lr_schedules.py#L47) (don't include any parentheses).\n",
    "    - A learning rate scheduler is a function that determines the learning rate depending on the training step.  For example, it may make sense to have the learning rate get smaller as the model gets closer to the optimal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View learning rate functions that you could choose from\n",
    "help(trax.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice three learning rate schedules to choose from are:\n",
    "\n",
    "```CPP\n",
    "EvalAdjustingSchedule\n",
    "MultifactorSchedule\n",
    "PolicySchedule\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View documentation for trax.lr.MultifactorSchedule\n",
    "help(trax.lr.MultifactorSchedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose value for the `inputs` parameter:\n",
    "    - Feed in the inputs that you created from calling `trax.supervised.Inputs`.\n",
    "- Choose and `output_dir` output directory:\n",
    "    - This is the folder where your model will be saved.\n",
    "    - We've chosen the directory '~/train_dir/' for the output directory.\n",
    "\n",
    "Use `os.path.expanduser()` to expand a shortcut for the path into the full path.\n",
    "- For example, expand `~/tmp_dir/`, where `~` refers to the home directory, so that it shows the full path: `/home/jovyan/tmp_dir/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study an example of expanding a directory path\n",
    "tmp_dir = '~/tmp_dir/'\n",
    "tmp_dir_expand = os.path.expanduser(tmp_dir)\n",
    "print(tmp_dir_expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you define the model using `trax.supervised.Trainer`, train the model over a chosen number of epochs\n",
    "- One `epoch` is a full set of training steps and evaluation on validation data.\n",
    "\n",
    "For each epoch, call the `trainer`'s `.train_epoch(n_steps=..., n_eval_steps=...)` function.\n",
    "- `n_steps`: number of batches to train in one epoch. For example, if n_steps is 100, then it will train for 100 batches and then output evaluation metrics such as accuracy, before moving onto the next epoch.\n",
    "- `n_eval_steps`: number of batches of the validation set to use when evaluating on the validation data (such as calculating accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trax.supervised.Trainer.train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex06'></a>\n",
    "### Exercise 06\n",
    "Implement `train_model` to define the model and then train it for the given number of epochs and training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kOX_GK1hfboK"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_model\n",
    "def train_model(classifier, n_epochs, train_steps, eval_steps, output_dir='~/train_dir/'):\n",
    "    '''\n",
    "    Input: \n",
    "    classifier - the model you are building\n",
    "    n_epochs - number of times to go over all the data\n",
    "    train_steps - number of training steps\n",
    "    eval_steps - the evaluation steps\n",
    "    output_dir - folder to save your files\n",
    "    Output:\n",
    "    trainer -  object ready for training\n",
    "    '''\n",
    "### START CODE HERE ###    \n",
    "    # Expand the output directory to the full path name\n",
    "    output_dir = os.path.expanduser(output_dir)\n",
    "\n",
    "    # Create a trax.supervised.Trainer object\n",
    "    trainer = trax.supervised.Trainer(\n",
    "        model=None, # classifier function which you defined before\n",
    "        loss_fn=None, # cross entropy loss\n",
    "        optimizer=None,  # adam optimizer\n",
    "        lr_schedule=None,  # Change lr schedule here. What is multi... schedule https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/lr_schedules.py#L47\n",
    "        inputs=None, # Processed inputs\n",
    "        output_dir=None,\n",
    "        random_seed=271)\n",
    "    \n",
    "    # iterate through each epoch\n",
    "    for _ in range(None): # complete this line\n",
    "        \n",
    "        # call the trainer's train_epoch function\n",
    "        # set n_steps and n_eval_steps\n",
    "        trainer.train_epoch(n_steps=None,\n",
    "                            n_eval_steps=None)\n",
    "        \n",
    "### END CODE HERE ###\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out train_model\n",
    "# Use 1 epoch and 200 training steps\n",
    "# This takes about 30 seconds to run. \n",
    "n_epochs  = 1\n",
    "train_steps = 200\n",
    "eval_steps = 10 \n",
    "tmp_output_dir = '~/model1/' # remove previous model.pkl\n",
    "!rm -f {tmp_output_dir}/model.pkl\n",
    "trainer_1 = train_model(classifier, n_epochs, train_steps, eval_steps, output_dir=tmp_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected output\n",
    "```CPP\n",
    "Step    200: Ran 200 train steps in 13.81 secs\n",
    "Step    200: Evaluation\n",
    "Step    200: train                   accuracy |  0.94375002\n",
    "Step    200: train                       loss |  0.24765237\n",
    "Step    200: train         neg_log_perplexity | -0.24765237\n",
    "Step    200: train          sequence_accuracy |  0.94375002\n",
    "Step    200: train weights_per_batch_per_core |  16.00000000\n",
    "Step    200: eval                    accuracy |  0.98124999\n",
    "Step    200: eval                        loss |  0.25154954\n",
    "Step    200: eval          neg_log_perplexity | -0.25154954\n",
    "Step    200: eval           sequence_accuracy |  0.98124999\n",
    "Step    200: eval  weights_per_batch_per_core |  16.00000000\n",
    "Step    200: Finished evaluation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "Fl_KgDd0gw9i",
    "outputId": "86eb584d-4fa2-45b0-9995-d7c402f6cc58"
   },
   "outputs": [],
   "source": [
    "# Try out your model with different hyperparameters\n",
    "# Use 4 epochs and 50 training steps per epoch\n",
    "# This takes about 30 seconds to run. \n",
    "n_epochs  = 4\n",
    "train_steps = 50\n",
    "eval_steps = 10 \n",
    "tmp_output_dir_2 = '~/model2/' # remove previous model.pkl\n",
    "!rm -f {tmp_output_dir_2}/model.pkl\n",
    "trainer_2 = train_model(classifier, n_epochs, train_steps, eval_steps, output_dir=tmp_output_dir_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pSYDsW8igrhG"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```CPP\n",
    "Step     50: Ran 50 train steps in 10.79 secs\n",
    "Step     50: Evaluation\n",
    "Step     50: train                   accuracy |  0.61874998\n",
    "Step     50: train                       loss |  0.67425668\n",
    "Step     50: train         neg_log_perplexity | -0.67425668\n",
    "Step     50: train          sequence_accuracy |  0.61874998\n",
    "Step     50: train weights_per_batch_per_core |  16.00000000\n",
    "Step     50: eval                    accuracy |  0.50625002\n",
    "Step     50: eval                        loss |  0.68561053\n",
    "Step     50: eval          neg_log_perplexity | -0.68561053\n",
    "Step     50: eval           sequence_accuracy |  0.50625002\n",
    "Step     50: eval  weights_per_batch_per_core |  16.00000000\n",
    "Step     50: Finished evaluation\n",
    "\n",
    "Step    100: Ran 50 train steps in 1.06 secs\n",
    "Step    100: Evaluation\n",
    "Step    100: train                   accuracy |  0.86250001\n",
    "Step    100: train                       loss |  0.52874601\n",
    "Step    100: train         neg_log_perplexity | -0.52874601\n",
    "Step    100: train          sequence_accuracy |  0.86250001\n",
    "Step    100: train weights_per_batch_per_core |  16.00000000\n",
    "Step    100: eval                    accuracy |  0.81875002\n",
    "Step    100: eval                        loss |  0.53125608\n",
    "Step    100: eval          neg_log_perplexity | -0.53125608\n",
    "Step    100: eval           sequence_accuracy |  0.81875002\n",
    "Step    100: eval  weights_per_batch_per_core |  16.00000000\n",
    "Step    100: Finished evaluation\n",
    "\n",
    "Step    150: Ran 50 train steps in 0.48 secs\n",
    "Step    150: Evaluation\n",
    "Step    150: train                   accuracy |  0.95625001\n",
    "Step    150: train                       loss |  0.37101132\n",
    "Step    150: train         neg_log_perplexity | -0.37101132\n",
    "Step    150: train          sequence_accuracy |  0.95625001\n",
    "Step    150: train weights_per_batch_per_core |  16.00000000\n",
    "Step    150: eval                    accuracy |  0.93124998\n",
    "Step    150: eval                        loss |  0.39398065\n",
    "Step    150: eval          neg_log_perplexity | -0.39398065\n",
    "Step    150: eval           sequence_accuracy |  0.93124998\n",
    "Step    150: eval  weights_per_batch_per_core |  16.00000000\n",
    "Step    150: Finished evaluation\n",
    "\n",
    "Step    200: Ran 50 train steps in 1.05 secs\n",
    "Step    200: Evaluation\n",
    "Step    200: train                   accuracy |  0.96249998\n",
    "Step    200: train                       loss |  0.21740448\n",
    "Step    200: train         neg_log_perplexity | -0.21740448\n",
    "Step    200: train          sequence_accuracy |  0.96249998\n",
    "Step    200: train weights_per_batch_per_core |  16.00000000\n",
    "Step    200: eval                    accuracy |  0.96875000\n",
    "Step    200: eval                        loss |  0.24526033\n",
    "Step    200: eval          neg_log_perplexity | -0.24526033\n",
    "Step    200: eval           sequence_accuracy |  0.96875000\n",
    "Step    200: eval  weights_per_batch_per_core |  16.00000000\n",
    "Step    200: Finished evaluation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.2'></a>\n",
    "### Part 3.2 Initialize a model with the trained weights\n",
    "\n",
    "Now that you have trained a model, the weights are stored in the `trainer_1` and `trainer_2` objects.  To initialize a model based on these weights\n",
    "- Create an object based on the `classifier` that you defined.\n",
    "- initialize the model\n",
    "- assign the weights that were derived from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trax.shapes.ShapeDtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the model that is returned by your `classifier` function is of type `trax.layers.combinators.Serial`.  It has an init function `.init(input_signature=..., dtype=...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trax.layers.combinators.Serial.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of your classifier\n",
    "tmp_model = classifier()\n",
    "\n",
    "# Initialize the model, which is of type trax.layers.combinators.Serial \n",
    "tmp_model.init(input_signature=trax.shapes.ShapeDtype((1, 1), dtype=np.int32))\n",
    "\n",
    "# Assign the weights that you recently trained to the model\n",
    "# Use trainer_2 weights (it had higher accuracy compared to trainer_1)\n",
    "tmp_model.weights = trainer_2.model_weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3.3'></a>\n",
    "### Part 3.3 Practice Making a prediction\n",
    "\n",
    "Use the training data just to see how the prediction process works.  \n",
    "- Later, you will use validation data to evaluate your model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator object\n",
    "tmp_val_generator = val_generator(16)\n",
    "\n",
    "# get one batch\n",
    "tmp_batch = next(tmp_val_generator)\n",
    "\n",
    "# Position 0 has the model inputs (tweets as tensors)\n",
    "# position 1 has the targets (the actual labels)\n",
    "tmp_inputs, tmp_targets = tmp_batch\n",
    "\n",
    "print(f\"The batch is a tuple of length {len(tmp_batch)} because position 0 contains the tweets, and position 1 contains the targets.\") \n",
    "print(f\"The shape of the tweet tensors is {tmp_inputs.shape} (num of examples, length of tweet tensors)\")\n",
    "print(f\"The shape of the labels is {tmp_targets.shape}, which is the batch size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the tweet tensors into the model to get a prediction\n",
    "tmp_pred = tmp_model(tmp_inputs)\n",
    "print(f\"The prediction shape is {tmp_pred.shape}, num of tensor_tweets as rows\")\n",
    "print(\"Column 0 is the probability of a negative sentiment (class 0)\")\n",
    "print(\"Column 1 is the probability of a positive sentiment (class 1)\")\n",
    "print()\n",
    "print(\"View the prediction array\")\n",
    "tmp_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn these probabilities into categories (negative or positive sentiment prediction), for each row:\n",
    "- Compare the probabilities in each column.\n",
    "- If column 1 has a value greater than column 0, classify that as a positive tweet.\n",
    "- Otherwise if column 1 is less than or equal to column 0, classify that example as a negative tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn probabilites into category predictions\n",
    "tmp_is_positive = tmp_pred[:,1] > tmp_pred[:,0]\n",
    "for i, p in enumerate(tmp_is_positive):\n",
    "    print(f\"Neg prob {tmp_pred[i,0]:.4f}\\tPos prob {tmp_pred[i,1]:.4f}\\t is positive? {p}\\t actual {tmp_targets[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that since you are making a prediction using a training batch, it's more likely that the model's predictions match the actual targets (labels).  \n",
    "- Every prediction that the tweet is positive is also matching the actual target of 1 (positive sentiment).\n",
    "- Similarly, all predictions that the sentiment is not positive matches the actual target of 0 (negative sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more useful thing to know is how to compare if the prediction is matching the actual target (label).  \n",
    "- The result of calculation `is_positive` is a boolean.\n",
    "- The target is a type trax.math.numpy.int32\n",
    "- If you expect to be doing division, you may prefer to work with decimal numbers with the data type type trax.math.numpy.int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the array of booleans\n",
    "print(\"Array of booleans\")\n",
    "display(tmp_is_positive)\n",
    "\n",
    "# convert boolean to type int32\n",
    "# True is converted to 1\n",
    "# False is converted to 0\n",
    "tmp_is_positive_int = tmp_is_positive.astype(np.int32)\n",
    "\n",
    "\n",
    "# View the array of integers\n",
    "print(\"Array of integers\")\n",
    "display(tmp_is_positive_int)\n",
    "\n",
    "# convert boolean to type float32\n",
    "tmp_is_positive_float = tmp_is_positive.astype(np.float32)\n",
    "\n",
    "# View the array of floats\n",
    "print(\"Array of floats\")\n",
    "display(tmp_is_positive_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Python usually does type conversion for you when you compare a boolean to an integer\n",
    "- True compared to 1 is True, otherwise any other integer is False.\n",
    "- False compared to 0 is True, otherwise any ohter integer is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"True == 1: {True == 1}\")\n",
    "print(f\"True == 2: {True == 2}\")\n",
    "print(f\"False == 0: {False == 0}\")\n",
    "print(f\"False == 2: {False == 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we recommend that you keep track of the data type of your variables to avoid unexpected outcomes.  So it helps to convert the booleans into integers\n",
    "- Compare 1 to 1 rather than comparing True to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you are now familiar with what kinds of inputs and outputs the model uses when making a prediction.\n",
    "- This will help you implement a function that estimates the accuracy of the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fRRrgOHJgrhI"
   },
   "source": [
    "<a name='4'></a>\n",
    "# Part 4: Evaluation  \n",
    "\n",
    "<a name='4.1'></a>\n",
    "### 4.1 Computing the accuracy on a batch\n",
    "\n",
    "You will now write a function that evaluates your model on the validation set and returns the accuracy. \n",
    "- `preds` contains the predictions.\n",
    "    - Its dimensions are `(batch_size, output_dim)`.  `output_dim` is two in this case.  Column 0 contains the probability that the tweet belongs to class 0 (negative sentiment). Column 1 contains probability that it belongs to class 1 (positive sentiment).\n",
    "    - If the probability in column 1 is greater than the probability in column 0, then interpret this as the model's prediction that the example has label 1 (positive sentiment).  \n",
    "    - Otherwise, if the probabilities are equal or the probability in column 0 is higher, the model's prediction is 0 (negative sentiment).\n",
    "- `y` contains the actual labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex07'></a>\n",
    "### Exercise 07\n",
    "Implement `compute_accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBqaN5f9grhJ"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_accuracy\n",
    "\n",
    "def compute_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        preds: a tensor of shape (dim_batch, output_dim) \n",
    "        y: a tensor of shape (dim_batch, output_dim) with the true labels\n",
    "    Output: \n",
    "        accuracy: a float between 0-1 \n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Create an array of booleans, \n",
    "    # True if the probability of positive sentiment is greater than\n",
    "    # the probability of negative sentiment\n",
    "    # else False\n",
    "    is_pos =  None\n",
    "\n",
    "    # convert the array of booleans into an array of np.int32\n",
    "    is_pos_int = None\n",
    "    \n",
    "    # compare the array of predictions (as int32) with the target (labels) of type int32\n",
    "    correct = None\n",
    "\n",
    "    # Count the number of predictions\n",
    "    num_predictions = None\n",
    "    \n",
    "    # convert the array of correct predictions (boolean) into an arrayof np.float32\n",
    "    correct_float = None\n",
    "    \n",
    "    # Sum up the correct predictions (of type np.float32) \n",
    "    num_correct = None\n",
    "\n",
    "    # Divide the number of correct predictions by the number of total predictions\n",
    "    accuracy = num_correct / num_predictions\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return accuracy, num_correct, num_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your function\n",
    "tmp_val_generator = val_generator(16)\n",
    "\n",
    "# get one batch\n",
    "tmp_batch = next(tmp_val_generator)\n",
    "\n",
    "# Position 0 has the model inputs (tweets as tensors)\n",
    "# position 1 has the targets (the actual labels)\n",
    "tmp_inputs, tmp_targets = tmp_batch\n",
    "\n",
    "# feed the tweet tensors into the model to get a prediction\n",
    "tmp_pred = tmp_model(tmp_inputs)\n",
    "\n",
    "tmp_acc, tmp_num_correct, tmp_num_predictions = compute_accuracy(preds=tmp_pred, y=tmp_targets)\n",
    "\n",
    "print(f\"Model's prediction accuracy on a single training batch is: {100 * tmp_acc}%\")\n",
    "print(f\"Number of correct predictions {tmp_num_correct}; number of total observations predicted {tmp_num_predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected output\n",
    "\n",
    "```\n",
    "Model's prediction accuracy on a single training batch is: 93.75%\n",
    "Number of correct predictions 15.0; number of total observations predicted 16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqle69F1grhM"
   },
   "source": [
    "<a name='4.2'></a>\n",
    "### 4.2 Testing your model on Validation Data\n",
    "\n",
    "Now you will write test your model's prediction accuracy on validatio data. \n",
    "\n",
    "This program will take in a data generator and your model. \n",
    "- The generator allows you to get batches of data. You can use it with a `for` loop:\n",
    "\n",
    "```\n",
    "for batch in iterator: \n",
    "   # do something with that batch\n",
    "```\n",
    "\n",
    "`batch` has dimensions `(batch size, 2)`. \n",
    "- Column 0 corresponds to the tweet as a tensor.\n",
    "- Column 1 corresponds to its target (actual label, positive or negative sentiment).\n",
    "- You can feed the tweet into model and it will return the predictions for the batch. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex08'></a>\n",
    "### Exercise 08\n",
    "\n",
    "**Instructions:** \n",
    "- Compute the accuracy over all the batches in the validation iterator. \n",
    "- Make use of `compute_accuracy`, which you recently implemented, and return the overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKoTad4ggrhN"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: test_model\n",
    "\n",
    "def test_model(generator, model):\n",
    "    '''\n",
    "    Input: \n",
    "        generator: an iterator instance that provides batches of inputs and targets\n",
    "        model: a model instance \n",
    "    Output: \n",
    "        acc: float corresponding to the accuracy\n",
    "    '''\n",
    "    \n",
    "    accuracy = 0.\n",
    "    total_num_correct = 0\n",
    "    total_num_pred = 0\n",
    "    count = 0\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    for batch in generator: \n",
    "        \n",
    "        # Retrieve the inputs from the batch\n",
    "        inputs = None\n",
    "        \n",
    "        # Retrieve the targets (actual labels) from the batch\n",
    "        targets = None\n",
    "        \n",
    "        # Make predictions using the inputs\n",
    "        pred = None\n",
    "        \n",
    "        # Calculate accuracy for the batch by comparing its predictions and targets\n",
    "        batch_accuracy, batch_num_correct, batch_num_pred = None \n",
    "        \n",
    "        # Update the total number of correct predictions\n",
    "        # by adding the number of correct predictions from this batch\n",
    "        total_num_correct += None\n",
    "        \n",
    "        # Update the total number of predictions \n",
    "        # by adding the number of predictions made for the batch\n",
    "        total_num_pred += None\n",
    "\n",
    "    # Calculate accuracy over all examples\n",
    "    accuracy = None\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1Rm_k21XgrhQ",
    "outputId": "1b67d785-db2e-4390-aa9a-dc1be9279b78"
   },
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# testing the accuracy of your model: this takes around 20 seconds\n",
    "model = classifier() # creates an instance of your classifier\n",
    "model.init(trax.shapes.ShapeDtype((1, 1), dtype=np.int32))\n",
    "model.weights = trainer_2.model_weights # Assigned trained model weights to the model\n",
    "\n",
    "accuracy = test_model(val_generator(16), model)\n",
    "\n",
    "print(f'The accuracy of your model on the validation set is {accuracy:.4f}', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "esUJRMQPgrhS"
   },
   "source": [
    "##### Expected Output\n",
    "\n",
    "```CPP\n",
    "The accuracy of your model on the validation set is 0.9640\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mct4P9QZgrhT"
   },
   "source": [
    "<a name='5'></a>\n",
    "# Part 5: Testing with your own input\n",
    "\n",
    "Finally you will test with your own input. You will see that deepnets are more powerful than the older methods you have used before. Although you go close to 100% accuracy on the first two assignments, the task was way easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SUq5cw-xgrhU"
   },
   "outputs": [],
   "source": [
    "# this is used to predict on your own sentnece\n",
    "def predict(sentence):\n",
    "    inputs = np.array(tweet_to_tensor(sentence, vocab_dict=Vocab))\n",
    "    \n",
    "    # Batch size 1, add dimension for batch, to work with the model\n",
    "    inputs = inputs[None, :]  \n",
    "    \n",
    "    # predict with the model\n",
    "    preds_probs = model(inputs)\n",
    "    \n",
    "    # Turn probabilities into categories\n",
    "    preds = int(preds_probs[0, 1] > preds_probs[0, 0])\n",
    "    \n",
    "    sentiment = \"negative\"\n",
    "    if preds == 1:\n",
    "        sentiment = 'positive'\n",
    "\n",
    "    return preds, sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3RJntC57grhX",
    "outputId": "1b17bc9c-30e4-4e13-b4c9-c420796ea1b1"
   },
   "outputs": [],
   "source": [
    "# try a positive sentence\n",
    "sentence = \"It's such a nice day, think i'll be taking Sid to Ramsgate, fish and chips for lunch at Peter's fish factory and then the beach maybe\"\n",
    "tmp_pred, tmp_sentiment = predict(sentence)\n",
    "print(f\"The sentiment of the sentence \\n***\\n\\\"{sentence}\\\"\\n***\\nis {tmp_sentiment}.\")\n",
    "\n",
    "print()\n",
    "# try a negative sentence\n",
    "sentence = \"I hated my day, it was the worst, I'm so sad.\"\n",
    "tmp_pred, tmp_sentiment = predict(sentence)\n",
    "print(f\"The sentiment of the sentence \\n***\\n\\\"{sentence}\\\"\\n***\\nis {tmp_sentiment}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model seems to prefer prediction positive sentiment, even for a sentence that looks negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNg0fAYIgrhd"
   },
   "source": [
    "### On Deep Nets\n",
    "\n",
    "Deep nets allow you to understand and capture dependencies that you would have not been able to capture with a simple linear regression, or logistic regression. \n",
    "- It also allows you to better use pre-trained embeddings for classification and tends to generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment_with_deep_nets_updated_Manish.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
